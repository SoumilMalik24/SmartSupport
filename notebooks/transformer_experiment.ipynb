{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e101e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SmartSupport\\.venv311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025/12/25 01:02:40 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/25 01:02:40 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/25 01:02:40 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/25 01:02:40 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/25 01:02:40 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/25 01:02:40 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:d:/SmartSupport/notebooks/mlruns/2', creation_time=1766595716293, experiment_id='2', last_update_time=1766595716293, lifecycle_stage='active', name='SmartSupport-Transformer-Research', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "mlflow.set_experiment(\"SmartSupport-Transformer-Research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b94fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef567f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wesentlicher Sicherheitsvorfall</td>\n",
       "      <td>Sehr geehrtes Support-Team,\\n\\nich möchte eine...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Disruption</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI am writing to...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Query About Smart Home System Integration Feat...</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inquiry Regarding Invoice Details</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question About Marketing Agency Software Compa...</td>\n",
       "      <td>Dear Support Team,\\n\\nI hope this message reac...</td>\n",
       "      <td>Problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0                    Wesentlicher Sicherheitsvorfall   \n",
       "1                                 Account Disruption   \n",
       "2  Query About Smart Home System Integration Feat...   \n",
       "3                  Inquiry Regarding Invoice Details   \n",
       "4  Question About Marketing Agency Software Compa...   \n",
       "\n",
       "                                                body      type  \n",
       "0  Sehr geehrtes Support-Team,\\n\\nich möchte eine...  Incident  \n",
       "1  Dear Customer Support Team,\\n\\nI am writing to...  Incident  \n",
       "2  Dear Customer Support Team,\\n\\nI hope this mes...   Request  \n",
       "3  Dear Customer Support Team,\\n\\nI hope this mes...   Request  \n",
       "4  Dear Support Team,\\n\\nI hope this message reac...   Problem  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../data/raw/tickets.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Use BOTH English + German (key difference vs LSTM)\n",
    "df = df[[\"subject\", \"body\", \"type\"]].reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d3df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"subject\"].fillna(\"\") + \" \" + df[\"body\"].fillna(\"\")\n",
    "df['text'] = df['text'].str.replace('\\\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9f9565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"type\"])\n",
    "num_labels = df[\"label\"].nunique()\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7509737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df[[\"text\", \"label\"]],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93b39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 22869/22869 [00:03<00:00, 6917.10 examples/s]\n",
      "Map: 100%|██████████| 5718/5718 [00:00<00:00, 8284.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"xlm-roberta-base\"  # multilingual\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df).map(tokenize, batched=True)\n",
    "test_ds  = Dataset.from_pandas(test_df).map(tokenize, batched=True)\n",
    "\n",
    "train_ds = train_ds.remove_columns([\"text\"])\n",
    "test_ds  = test_ds.remove_columns([\"text\"])\n",
    "train_ds.set_format(\"torch\")\n",
    "test_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d538831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f39f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81c4b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./transformer_out\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=8,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a43a412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_27540\\706959913.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='151' max='34305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  151/34305 06:29 < 24:48:39, 0.38 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      8\u001b[39m mlflow.log_param(\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m16\u001b[39m)\n\u001b[32m     10\u001b[39m trainer = Trainer(\n\u001b[32m     11\u001b[39m     model=model,\n\u001b[32m     12\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m eval_metrics = trainer.evaluate()\n\u001b[32m     22\u001b[39m mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m, eval_metrics[\u001b[33m\"\u001b[39m\u001b[33meval_accuracy\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SmartSupport\\.venv311\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SmartSupport\\.venv311\\Lib\\site-packages\\transformers\\trainer.py:2756\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2754\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m) / steps_in_epoch\n\u001b[32m   2755\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2756\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2757\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2758\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2759\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2760\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2761\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2762\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2763\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2764\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2765\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2766\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2767\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\SmartSupport\\.venv311\\Lib\\site-packages\\transformers\\trainer.py:3200\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3197\u001b[39m logs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] = {}\n\u001b[32m   3199\u001b[39m \u001b[38;5;66;03m# all_gather + mean() to get average loss over all processes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3200\u001b[39m tr_loss_scalar = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_nested_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3202\u001b[39m \u001b[38;5;66;03m# reset tr_loss to zero\u001b[39;00m\n\u001b[32m   3203\u001b[39m tr_loss -= tr_loss\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"xlm_roberta_multilingual\"):\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"Transformer\")\n",
    "    mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "    mlflow.log_param(\"languages\", \"en+de\")\n",
    "    mlflow.log_param(\"max_length\", 128)\n",
    "    mlflow.log_param(\"epochs\", 3)\n",
    "    mlflow.log_param(\"batch_size\", 16)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_metrics = trainer.evaluate()\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", eval_metrics[\"eval_accuracy\"])\n",
    "    mlflow.log_metric(\"macro_f1\", eval_metrics[\"eval_macro_f1\"])\n",
    "\n",
    "    mlflow.pytorch.log_model(model, artifact_path=\"transformer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20857a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
