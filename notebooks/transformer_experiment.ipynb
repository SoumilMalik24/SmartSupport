{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e101e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/SmartSupport/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-01-05 05:18:23.051818: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/workspace/SmartSupport/venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "2026/01/05 05:18:26 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/05 05:18:26 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2026/01/05 05:18:26 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/05 05:18:27 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/05 05:18:27 INFO mlflow.tracking.fluent: Experiment with name 'SmartSupport-Transformer-Research' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspace/SmartSupport/notebooks/mlruns/1', creation_time=1767590307289, experiment_id='1', last_update_time=1767590307289, lifecycle_stage='active', name='SmartSupport-Transformer-Research', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "mlflow.set_experiment(\"SmartSupport-Transformer-Research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b94fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef567f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wesentlicher Sicherheitsvorfall</td>\n",
       "      <td>Sehr geehrtes Support-Team,\\n\\nich möchte eine...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Disruption</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI am writing to...</td>\n",
       "      <td>Incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Query About Smart Home System Integration Feat...</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inquiry Regarding Invoice Details</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question About Marketing Agency Software Compa...</td>\n",
       "      <td>Dear Support Team,\\n\\nI hope this message reac...</td>\n",
       "      <td>Problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0                    Wesentlicher Sicherheitsvorfall   \n",
       "1                                 Account Disruption   \n",
       "2  Query About Smart Home System Integration Feat...   \n",
       "3                  Inquiry Regarding Invoice Details   \n",
       "4  Question About Marketing Agency Software Compa...   \n",
       "\n",
       "                                                body      type  \n",
       "0  Sehr geehrtes Support-Team,\\n\\nich möchte eine...  Incident  \n",
       "1  Dear Customer Support Team,\\n\\nI am writing to...  Incident  \n",
       "2  Dear Customer Support Team,\\n\\nI hope this mes...   Request  \n",
       "3  Dear Customer Support Team,\\n\\nI hope this mes...   Request  \n",
       "4  Dear Support Team,\\n\\nI hope this message reac...   Problem  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../data/raw/tickets.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Use BOTH English + German (key difference vs LSTM)\n",
    "df = df[[\"subject\", \"body\", \"type\"]].reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d3df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"subject\"].fillna(\"\") + \" \" + df[\"body\"].fillna(\"\")\n",
    "df['text'] = df['text'].str.replace('\\\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9f9565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"type\"])\n",
    "num_labels = df[\"label\"].nunique()\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7509737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df[[\"text\", \"label\"]],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93b39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 22869/22869 [00:03<00:00, 6957.18 examples/s]\n",
      "Map: 100%|██████████| 5718/5718 [00:00<00:00, 6446.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"xlm-roberta-base\"  # multilingual\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df).map(tokenize, batched=True)\n",
    "test_ds  = Dataset.from_pandas(test_df).map(tokenize, batched=True)\n",
    "\n",
    "train_ds = train_ds.remove_columns([\"text\"])\n",
    "test_ds  = test_ds.remove_columns([\"text\"])\n",
    "train_ds.set_format(\"torch\")\n",
    "test_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d538831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f39f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81c4b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./transformer_out\",\n",
    "\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    gradient_accumulation_steps=2,  \n",
    "\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "\n",
    "    logging_steps=50,\n",
    "\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a43a412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1904/1005552869.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4290' max='4290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4290/4290 15:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.377144</td>\n",
       "      <td>0.812172</td>\n",
       "      <td>0.791127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324700</td>\n",
       "      <td>0.360536</td>\n",
       "      <td>0.833683</td>\n",
       "      <td>0.840467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.371282</td>\n",
       "      <td>0.845575</td>\n",
       "      <td>0.853809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [358/358 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"xlm_roberta_multilingual\"):\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"Transformer\")\n",
    "    mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "    mlflow.log_param(\"languages\", \"en+de\")\n",
    "    mlflow.log_param(\"max_length\", 128)\n",
    "    mlflow.log_param(\"epochs\", 3)\n",
    "    mlflow.log_param(\"batch_size\", 16)\n",
    "    mlflow.log_param(\"fp16\", True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_metrics = trainer.evaluate()\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", eval_metrics[\"eval_accuracy\"])\n",
    "    mlflow.log_metric(\"macro_f1\", eval_metrics[\"eval_macro_f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20857a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (smart_support_venv)",
   "language": "python",
   "name": "smart_support_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
